<!DOCTYPE html>
<html>
<head>
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-F28Q22D1LS"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-F28Q22D1LS');
  </script>
  <meta charset="utf-8">
  <meta name="description" content="DiPPeR: Diffusion-based 2D Path Planner applied on Legged Robots">
  <meta name="keywords" content="Path Planing, Diffusion, Quadrupedal Robots">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>DiPPeST: Diffusion-based Path Planner for Synthesizing&#10; Trajectories Applied on Quadruped Robots</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.3.1/dist/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">

  <script src="https://www.youtube.com/iframe_api"></script>
  <script src="./static/js/ajax.googleapis.com_ajax_libs_jquery_3.5.1_jquery.min.js"></script>
  <script src="./static/js/isInViewport.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>

  <link rel="icon" href="./favicon.ico?">
  
</head>
<body>
  
  
<section class="hero">
  <div class="hero-body">
    <div class="container">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">DiPPeST: Diffusion-based Path Planner for Synthesizing Trajectories Applied on Quadruped Robots</h1>
          <div class="is-size-4 publication-authors">
            <span class="author-block">
              <a href="https://rpl-as-ucl.github.io/people/">Maria Stamatopoulou*</a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
              <a href="https://rpl-as-ucl.github.io/people/">Jianwei Liu*</a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
              <a href="https://dkanou.github.io/">Dimitrios Kanoulas</a>
              <br><br>
              <p>
                Robot Perception Lab (<a href="https://rpl-as-ucl.github.io">RPL</a>), Computer Science @ UCL.
              <br><br>
              <p>
                (Webpage Under development)
              <br><br>
              <img src="./resources/planning_rw.png" width="800"></img>
              <!-- <span class="brmod"><b>ICRA 2024 Submission</b></span> -->
            </span>
          </div>

<div class="column has-text-centered">
<!-- arXiv Link. -->
  <span class="link-block">
    <a href="http://arxiv.org/abs/2310.07842"
      class="external-link button is-normal is-rounded is-dark">
      <span class="icon">
        <i class="ai ai-arxiv"></i>
      </span>
      <span>arXiv</span>
    </a>
  </span>

  <!-- Video Link. -->
  <span class="link-block">
    <a href="https://youtu.be/alTwmPyMnig?si=JM_fFBjeDMlrk55H"
      class="external-link button is-normal is-rounded is-dark">
      <span class="icon">
        <i class="fab fa-youtube"></i>
      </span>
      <span>Video</span>
    </a>
  </span>
</div>       
  
<section class="section">
  <div class="container">
    <br>
    <br>
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-two-thirds">
        <h3 class="title is-2">Abstract</h3>
        <div class="content has-text-justified">
          <p>
          We present DiPPeST, a novel image and goal conditioned diffusion-based trajectory generator for quadrupedal robot path planning. DiPPeST is a zero-shot adaptation of our previously introduced diffusion-based 2D global trajectory generator (<a href="https://rpl-cs-ucl.github.io/DiPPeR/">DiPPeR</a>). The introduced system incorporates a novel strategy for local real-time path refinements, that is re- active to camera input, without requiring any further training, image processing, or environment interpretation techniques. DiPPeST achieves 92% success rate in obstacle avoidance for nominal environments and an average of 88% success rate when tested in environments that are up to 3.5 times more complex in pixel variation than DiPPeR. A visual-servoing framework is developed to allow for real-world execution, tested on the quadruped robot, achieving 80% success rate in different environments and showcasing improved behavior than complex state-of-the-art local planners, in narrow environments.
          </p>
          <p>
           In the following sections we present DiPPeSTs performance and genarilisation capabilities.
          </p>
          <br></br>
        </div>
        <div class="is-centered">
          <!--<center>
          <video autoplay muted loop playsinline controls poster="./resources/loading-icon.gif" style="width: 95%; border: 1px solid #bbb; border-radius: 10px; margin: 2.0%;">
          <source src="./resources/real_world/map2spot.mp4" type="video/mov">
          </video>
          </center>--> 
      </div>
      </div>
    </div>
  </div>

<section class="section">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-full-width">
        <br>
        <h2 class="title is-2" style="text-align: center; padding-bottom: 12px;">Genarilisation Performance</h2>
        <br>
        <h5>
          <center>
           We validate DiPPeST's generalisation capabilites for variation of input image size, pixel intensity variation and point of view, as DiPPeR was trained in top-down view black and white maps desplyed bellow.
          </center>
        </h5>
        <br></br>
        <td>
          <div class="row">
            <div class="col">
                <video autoplay muted loop playsinline controls src="./resources/dipper/VAL_1_short.mp4" width="50%"
                       style="border-radius:10px; "></video>
            </div>
            <div class="col">
              <video autoplay muted loop playsinline controls src="./resources/dipper/VAL_4_midium.mp4" width="50%"
              style="border-radius:10px; "></video>
            </div>
            <div class="col">
              <video autoplay muted loop playsinline controls src="./resources/dipper/LONGUSE2.mp4" width="50%"
                      style="border-radius:10px; "></video>
              </div>
              <br></br>
            </div>
            <br></br>
          </td>
        </tr>
        <h3 class="title" style="text-align: center; padding-bottom: 7px;"> Variation of Floor and Obstacle Pixel Intensity</h3>
        <br>
        <h5>
          <center>
           We investigate the cases where the obstacles are similar in pixel intensity (PI) to the traversable region or the traversible region includes pixels of multiple intensities, to showcase DiPPeST can generate paths beyond white trversable and balck non traversable regions</h5>
         </center>
        </h5>
        <br></br>
        <td>
            <div class="row">
              <div class="col">
                  <video autoplay muted loop playsinline controls src="./resources/edge_cases/edge1u.mp4" width="100%"
                         style="border-radius:10px; "></video>
              </div>
              <div class="col">
                <video autoplay muted loop playsinline controls src="./resources/edge_cases/edge2u.mp4" width="100%"
                       style="border-radius:10px; "></video>
              </div>
              <div class="col">
                <video autoplay muted loop playsinline controls src="./resources/edge_cases/edge3u.mp4" width="100%"
                       style="border-radius:10px; "></video>
              </div>
              <br></br>
            </div>
          </td>
        </tr>
        <td>
          <div class="row">
            <div class="col">
                <h5> Obstacle-Floor PI Difference = 26%</h5>
            </div>
            <div class="col">
              <h5> Obstacle-Floor PI Difference = 28%</h5>
            </div>
            <div class="col">
              <h5> Image PI Variation = 82% </h5>
            </div>
            <br></br>
          </div>
        </td>
      </div> 
    </div>
  </div>
</section>

<section class="section">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h3 class="title" style="text-align: center; padding-bottom: 7px;">Variation of Input Image Size</h3>
        <h5>
        <center>
          DiPPeST receives camera input, which may have a variable FoV based on hardware specifications.
        </center>
        </h5>
          <br>
          <td>
            <div class="row">
              <div class="col">
                  <video autoplay muted loop playsinline controls src="./resources/size/size1.mp4" width="100%"
                         style="border-radius:10px; "></video>
              </div>
              <div class="col">
                <video autoplay muted loop playsinline controls src="./resources/size/size2.mp4" width="100%"
                       style="border-radius:10px; "></video>
              </div>
              <div class="col">
                <video autoplay muted loop playsinline controls src="./resources/size/size3.mp4" width="100%"
                       style="border-radius:10px; "></video>
              </div>
            </div>
          </td>
        </tr>
        <td>
          <div class="row">
            <div class="col">
              <h5> Training Dataset: [100,3,3]</h5>
            </div>
            <div class="col">
              <h5> iPhone 11 Camera: [3264,2448,3] </h5>
            </div>
            <div class="col">
              <h5>  RealSense D435i Camera [720,1280,3] </h5>
            </div>
            <br></br>
          </div>
        </td>
      </div> 
    </div>
  </div>
</section>

<section class="section">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h3 class="title" style="text-align: center; padding-bottom: 7px;">Variation of Camera Point-of-View</h3>
        <h5>
          <center>
          DiPPeST should generalize to input images of varying PoV, reflecting variations in camera angle and heights in real-world scenarios.
          </center>
        </h5>
        <br></br>
          <td>
            <div class="row">
              <div class="col">
                  <video autoplay muted loop playsinline controls src="./resources/pov/pov1.mp4" width="100%"
                         style="border-radius:10px; "></video>
              </div>
              <div class="col">
                <video autoplay muted loop playsinline controls src="./resources/pov/pov2.mp4" width="100%"
                       style="border-radius:10px; "></video>
              </div>
              <div class="col">
                <video autoplay muted loop playsinline controls src="./resources/pov/pov3.mp4" width="100%"
                       style="border-radius:10px; "></video>
              </div>
            </div>
            <br>
          </td>
        </tr>
        <td>
          <div class="row">
            <div class="col">
              <h5> Top-Down</h5>
            </div>
            <div class="col">
              <h5> Human-View </h5>
            </div>
            <div class="col">
              <h5>Robot-View</h5>
            </div>
            <br></br>
          </div>
        </td>
      </div> 
    </div>
  </div>
</section>


<section class="section">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-full-width">
        <br> <br>
        <h3 class="title is-2" style="text-align: center; padding-bottom: 10px;">Real World Deployment</h3>
         <h5>
            <center>
              For real-world evaluation, the Unitree Go1 robot is used with DiPPeST, taking as input images from an Intel RelSense D435i camera mounted on the front at an angle of 10 degree depression. For all experiments, 
              the global plan is generated from the first frame (Sec. IV-A) while the robot remains stationary. 
              We test DiPPeSTâ€™s performance for a) static environments and b) dynamic environments by measuring the
               rate of successful attempts in avoiding obstacles and reaching the goal position across all attempts. 
            </center>
         </h5>
         <br></br>
         <h3>Static environments</h3>
         
         <h5> 
          <center>
            DiPPeST
          </center>
        </h5>
        <br></br>
          <td>
              <div class="row">
                  <video autoplay muted loop playsinline controls src="./resources/real_world/real1.mov" width="100%"
                         style="border-radius:10px; "></video>
              </div>
          <br></br>
          <h5> 
            <center>
              IPlanner
            </center>
          </h5>
          <br></br>
          <div class="row">
            <video autoplay muted loop playsinline controls src="./resources/real_world/real2.mov" width="100%"
                    style="border-radius:10px; "></video>
          </div>
            <h5> 
              <center>
                NoMaD
              </center>
            </h5>
            <br></br>
            <div class="row">
              <video autoplay muted loop playsinline controls src="./resources/real_world/real3.mov" width="100%"
                      style="border-radius:10px; "></video>
          </div>
            <br>
          </td>
        </tr>
        <br></br>
        <!-- <h3>Dynamic environments</h3>
        <br></br>
        <td>
          <div class="row">
              <video autoplay muted loop playsinline controls src="./resources/real_world/real1.mov" width="100%"
                     style="border-radius:10px; "></video>
          </div>
          <div class="row">
            <video autoplay muted loop playsinline controls src="./resources/real_world/real2.mov" width="100%"
                   style="border-radius:10px; "></video>
          </div>
          <div class="row">
            <video autoplay muted loop playsinline controls src="./resources/real_world/real3.mov" width="100%"
                   style="border-radius:10px; "></video>
        </div> -->
        <br>
      </td>
      </div> 
    </div>
  </div>
</section>

<!-- <section class="section" id="BibTeX">
  <div class="container content">
    <div align="left";>

    <h2 class="titile">BibTeX</h2>
    <pre><code>
      @article{liu2024dipper,
      title     = {DiPPeR: Diffusion-based 2D Path Planner applied on Legged Robots},
      author    = {Jianwei Liu, Maria Stamatopoulou, Dimitrios Kanoulas},
      journal   = {arXiv preprint arXiv:2309.14341},
      year      = {2024}
}
</div>
</code></pre>
  </div>
</section> -->

</body>

</html>
